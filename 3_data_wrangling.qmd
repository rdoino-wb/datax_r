---
title: "Efficient Data Analysis with `data.table`"
subtitle: "`R` Training"
institute: The World Bank Group - DataTax
date: today
author: ""
date-format: "dddd, [the] D[<sup style='font-size:65%;font-style:italic;'>th</sup>] [of] MMMM, YYYY"
output-dir: "_site/"
format:
  revealjs:
    theme: _extensions/dime-worldbank/dime/dime.scss
    # Output file
    output-file: 3_data_table.html
    code-line-numbers: true
    # Table of Contents
    toc: false
    toc_float: false
    toc-depth: 1
    toc-location: left
    toc-title: "Agenda"
    # Generate a self contained file
    self-contained: true
    self-contained-math: true
    # Turn preview links within the presentation off (all links open in a new tab)
    preview-links: true
    auto-animate: true
    # Logo and footer options
    logo: "logos/WB-DEC-Impact-horizontal-RGB-high.png"
    footer: "Code available on [GitHub](https://github.com/rdoino-wb/data_analysis_DataTable)."
---

```{r set-up}
#| include: false

library(emo)
library(countdown)
library(data.table)
library(here)

set.seed(123)

# Load the data from previous modules

dt_firms <- fread(here("r_training_datax", "data", "Intermediate", "dt_firms.csv"))
panel_vat <- fread(here("r_training_datax","data", "Intermediate", "panel_vat.csv"))
panel_cit <- fread(here("r_training_datax","data", "Intermediate", "panel_cit.csv"))
```

# Introduction {background-color="#07202E"}

## Why `data.table`? 

**Concise Code**

```{r, echo = T, results = "hide", eval = F}
# Traditional R approach: Calculate average VAT by firm size
# Step 1: Merge data
vat_firms <- merge(panel_vat, dt_firms, by = "firm_id")
# Step 2: Filter year
vat_firms_2023 <- vat_firms[vat_firms$year == 2023, ]
# Step 3: Calculate averages manually...

# data.table approach - one line!
panel_vat[dt_firms, on = "firm_id"][year == 2023, mean(vat_outputs), by = size]
```

::: {.callout-note}
Don't worry if this syntax looks strange! We'll learn each part step by step.
:::

---

## Why `data.table`? Speed Comparison

When processing tax data with millions of records:

- **Base R**: Processing 1 million records takes ~30 seconds
- **data.table**: Same operation takes <1 second `r emo::ji("zap")`

This matters when you're analyzing:
- All VAT declarations for the year
- Multi-year compliance patterns
- Real-time audit selection

---

## Why `data.table`? Memory Efficiency

**Why memory matters for tax data:**

If your computer runs out of memory, your analysis crashes. No result at all!

data.table uses 3-4x less memory than traditional R approaches:
- Process larger datasets on regular computers
- Run multiple analyses simultaneously
- No need for expensive hardware upgrades

---

## Why `data.table`? Simplicity

data.table has very few dependencies (only 1 other package).

This means:
- Fewer things can break
- Easier to install and maintain
- More stable over time
- Faster to load

Perfect for production environments in tax administrations!

# Getting Started with data.table {background-color="#07202E"}

---

## Installation and Setup

First, let's install and load data.table:

```{r installation, echo = T, eval = F}
# Install the package (only need to do this once)
install.packages("data.table")

# Load the package (do this every time you start R)
library(data.table)
```

Let's check our tax data from previous modules:

```{r check_data, echo = T, eval = T}
# Look at the structure of our VAT data
str(panel_vat)
```

::: {.callout-note}
The `str()` function shows the **structure** of your data - column names, types, and some values.
:::

--- 

## Understanding data.table Objects

In Module 1, we learned that R stores data in objects. In Module 2, we worked with data frames.

**data.table is a special type of data frame** - faster and more powerful:

```{r dt_check, echo = T, eval = T}
# Check what type of object panel_vat is
class(panel_vat)
```

Our data is already a data.table! That's because we used `fread()` to load it.

::: {.callout-tip}
`fread()` automatically creates data.tables when reading files - one less step for you!
:::

--- 

## Creating data.table Objects

There are 4 ways to create a data.table:

```{r class_3, echo = T, eval = F}
# 1. Create from scratch (like making a small test dataset)
test_data <- data.table(
  firm_id = c("FIRM_001", "FIRM_002", "FIRM_003"),
  vat_amount = c(50000, 75000, 30000)
)

# 2. Read from file (BEST method for real data!)
vat_data <- fread("data/vat_declarations.csv")

# 3. Convert an existing data frame
vat_dt <- as.data.table(existing_dataframe)

# 4. Convert "in place" (changes the original - be careful!)
setDT(existing_dataframe)
```

::: {.callout-warning}
Method 4 (`setDT`) permanently changes your original data frame. Only use it when you're sure!
:::

---

## The data.table Syntax

All data.table operations follow this simple pattern:

::: {.h-center-container}
### `DT[i, j, by]`
:::

Think of it like SQL:

| data.table | SQL Equivalent | What it does |
|------------|----------------|--------------|
| **i** | WHERE | Which rows to select |
| **j** | SELECT | Which columns or calculations |
| **by** | GROUP BY | How to group the data |

This should feel familiar if you know SQL!

::: {.callout-tip}
You can use any combination: just `i`, or `i` and `j`, or all three together.
:::

# Core Operations {background-color="#07202E"}

---

## Selecting Rows (the 'i' part)

Let's start with selecting specific rows:

```{r row_basic, echo = T, eval = T}
# Select first 3 rows (like SQL: LIMIT 3)
panel_vat[1:3]
```

::: {.callout-note}
In R, `1:3` means "numbers from 1 to 3" (1, 2, 3). We use this to select row numbers.
:::

---

## Filtering Rows with Conditions

Just like SQL WHERE clauses:

```{r row_filter, echo = T, eval = T}
# Select high-value VAT outputs (like SQL: WHERE vat_outputs > 100000)
high_vat <- panel_vat[vat_outputs > 100000]

# Show first 5 rows with specific columns
high_vat[1:5, .(firm_id, vat_outputs)]
```

::: {.callout-note}
`.(firm_id, vat_outputs)` is data.table's way of selecting columns. The dot `.` is shorthand for `list()`.
:::

---

## Multiple Conditions

Combine conditions using:
- `&` for AND
- `|` for OR
- `!` for NOT

```{r multiple_conditions, echo = T, eval = T}
# High outputs AND low inputs
panel_vat[vat_outputs > 100000 & vat_inputs < 50000][1:3]

# Using OR
panel_vat[vat_outputs > 200000 | vat_inputs > 200000][1:3]
```

---

## Ordering Data

Sort your data (like SQL ORDER BY):

```{r row_order, echo = T, eval = T}
# Order by VAT outputs (descending)
panel_vat[order(-vat_outputs)][1:3, .(firm_id, vat_outputs)]

# Order by multiple columns
panel_vat[order(firm_id, -vat_outputs)][1:5, .(firm_id, vat_outputs)]
```

::: {.callout-tip}
The minus sign `-` means descending order (highest to lowest).
:::

---

## Selecting Columns (the 'j' part)

Three ways to select columns:

```{r col_select, echo = T, eval = T}
# Method 1: Using .() notation
panel_vat[, .(firm_id, vat_inputs, vat_outputs)][1:3]

# Method 2: Using column numbers
panel_vat[, c(1, 3, 4)][1:3]

# Method 3: Using column names as character vector
cols_wanted <- c("firm_id", "vat_inputs", "vat_outputs")
panel_vat[, ..cols_wanted][1:3]
```

::: {.callout-note}
The `..` prefix tells data.table to look for `cols_wanted` as a variable, not a column name.
:::

---

## Creating New Columns

Add calculated columns using `:=` (assignment operator):

```{r col_add, echo = T, eval = T}
# Calculate net VAT (outputs minus inputs)
panel_vat[, net_vat := vat_outputs - vat_inputs]

# Check the result
panel_vat[1:3, .(firm_id, vat_inputs, vat_outputs, net_vat)]
```

::: {.callout-important}
`:=` modifies your data.table directly - no need to reassign like `panel_vat <- panel_vat[...]`
:::

---

## Multiple New Columns

Create several columns at once:

```{r col_multiple, echo = T, eval = T}
# Extract date parts and calculate ratios
panel_vat[, ':='(
  year = year(declaration_date),
  month = month(declaration_date),
  quarter = quarter(declaration_date),
  vat_ratio = vat_inputs / vat_outputs
)]

# View the new columns
panel_vat[1:3, .(firm_id, year, month, quarter, vat_ratio)]
```

::: {.callout-note}
`year()`, `month()`, and `quarter()` are functions that extract parts of dates.
:::

---

## Summary Statistics

Calculate summary statistics (like SQL aggregation):

```{r col_summary, echo = T, eval = T}
# Calculate totals and averages
panel_vat[, .(
  total_inputs = sum(vat_inputs, na.rm = TRUE),
  total_outputs = sum(vat_outputs, na.rm = TRUE),
  avg_net_vat = mean(net_vat, na.rm = TRUE),
  num_declarations = .N
)]
```

::: {.callout-tip}
- `na.rm = TRUE` tells R to ignore missing values
- `.N` is a special symbol meaning "count of rows"
:::

---

## Grouping Data (the 'by' part)

Group operations (like SQL GROUP BY):

```{r by_basic, echo = T, eval = T}
# First, let's add firm data to our VAT data
vat_with_firms <- merge(panel_vat, dt_firms, by = c("firm_id", "year"))

# Average VAT by firm size
vat_with_firms[, .(avg_net_vat = mean(net_vat, na.rm = TRUE)), by = size]
```

---

## Grouping by Multiple Variables

```{r by_multiple, echo = T, eval = T}
# Count firms by size and industry
vat_with_firms[, .N, by = .(size, industry)][1:10]

# Calculate averages by size and industry
vat_with_firms[, .(
  avg_vat = mean(net_vat, na.rm = TRUE),
  num_firms = .N
), by = .(size, industry)][1:5]
```

---

## Adding Group Statistics to Each Row

Sometimes you want to add group statistics without summarizing:

```{r by_columns, echo = T, eval = T}
# Add industry average to each firm
vat_with_firms[, industry_avg := mean(net_vat, na.rm = TRUE), by = industry]

# Compare firm to industry average
vat_with_firms[, above_avg := net_vat > industry_avg]

# View results
vat_with_firms[1:5, .(firm_id, industry, net_vat, industry_avg, above_avg)]
```

---

## Combining Operations

Use all three parts together - this is where data.table shines!

```{r combine_all, echo = T, eval = T}
# For large firms in 2023, calculate average VAT by industry
result <- vat_with_firms[
  size == "large" & year == 2023,          # i: which rows
  .(avg_vat = mean(net_vat), count = .N),  # j: what to calculate
  by = industry                             # by: grouping
]

print(result)
```

Read this as: "Take vat_with_firms, filter to large firms in 2023, calculate average VAT and count, grouped by industry"

---

## Chaining Operations

You can chain multiple operations using `][`:

```{r chaining, echo = T, eval = T}
# Chain multiple steps
vat_with_firms[
  year == 2023                    # First: filter to 2023
][
  , .(total_vat = sum(net_vat)), by = size  # Then: sum by size
][
  order(-total_vat)               # Finally: order by total
]
```

This is like using multiple SQL operations in sequence!

---

## Exercise 1: Basic Operations {.exercise}

`r countdown::countdown(minutes = 10, seconds = 0, top = 0)`

```{r exercise1_basic, echo = T, eval = F}
# Exercise 1: Basic data.table Operations

# 1. Row Selection
# a) From panel_vat, select all records where vat_outputs > 50000
# b) Order the result by vat_outputs (highest first)

# 2. Column Operations  
# a) Create a new column 'vat_balance' = vat_outputs - vat_inputs
# b) Create a column 'is_refund' that is TRUE when vat_balance is negative

# 3. Summary Statistics
# Calculate:
# - Total VAT inputs
# - Total VAT outputs  
# - Number of refund cases
# - Average VAT balance

# 4. Grouping
# Using the merged vat_with_firms data:
# a) Calculate average VAT balance by firm size
# b) Count number of firms by industry
# c) Find the industry with highest total VAT
```

---

## Exercise 1: Solutions {.exercise}

```{r solutions1_basic, echo = T, eval = T}
# 1. Row Selection
# a) High VAT outputs
high_vat <- panel_vat[vat_outputs > 50000]

# b) Order by vat_outputs
high_vat_ordered <- high_vat[order(-vat_outputs)]

# 2. Column Operations
# a) Create vat_balance
panel_vat[, vat_balance := vat_outputs - vat_inputs]

# b) Create is_refund flag
panel_vat[, is_refund := vat_balance < 0]

# 3. Summary Statistics
panel_vat[, .(
  total_inputs = sum(vat_inputs, na.rm = TRUE),
  total_outputs = sum(vat_outputs, na.rm = TRUE),
  refund_cases = sum(is_refund, na.rm = TRUE),
  avg_balance = mean(vat_balance, na.rm = TRUE)
)]

# 4. Grouping
# a) Average by size
vat_with_firms[, .(avg_balance = mean(net_vat, na.rm = TRUE)), by = size]

# b) Count by industry
vat_with_firms[, .N, by = industry]

# c) Industry with highest VAT
vat_with_firms[, .(total_vat = sum(net_vat)), by = industry][order(-total_vat)][1]
```

# Merging Data {background-color="#07202E"}

---

## Why Merge Data?

In tax administration, data comes from multiple sources:
- Firm registry (characteristics)
- VAT system (declarations)
- CIT system (corporate tax)
- Payment systems

We need to combine these for complete analysis!

::: {.callout-note}
Merging in R is like JOIN in SQL. If you know SQL joins, this will feel familiar.
:::

---

## Basic Merge

The simplest merge combines two tables by common columns:

```{r merge_basic, echo = T, eval = T}
# Merge VAT data with firm characteristics
vat_complete <- merge(
  panel_vat,
  dt_firms,
  by = c("firm_id", "year")  # Common columns
)

# View result
vat_complete[1:3, .(firm_id, year, net_vat, size, industry)]
```

This is like SQL: `SELECT * FROM panel_vat JOIN dt_firms ON firm_id AND year`

---

## Types of Merges

Just like SQL joins, we have different types:

```{r join_types_demo, echo = T, eval = T}
# Inner join (default) - only matching records
inner <- merge(panel_vat, dt_firms, by = c("firm_id", "year"))

# Left join - keep all VAT records
left <- merge(panel_vat, dt_firms, by = c("firm_id", "year"), all.x = TRUE)

# How many records in each?
cat("Inner join:", nrow(inner), "rows\n")
cat("Left join:", nrow(left), "rows\n")
```

::: {.callout-tip}
Use `all.x = TRUE` for left join, `all.y = TRUE` for right join, `all = TRUE` for full outer join.
:::

---

## Handling Missing Data After Merges

After merging, some fields might be missing:

```{r merge_missing, echo = T, eval = T}
# Check for missing firm data after left join
left[is.na(size), .N]  # Count records with missing size

# Fill missing values
left[is.na(size), size := "Unknown"]
left[is.na(industry), industry := "Unknown"]

# Verify
left[size == "Unknown", .N]
```

::: {.callout-note}
`is.na()` checks for missing values (NA = Not Available).
:::

---

## Exercise 2: Merging {.exercise}

`r countdown::countdown(minutes = 10, seconds = 0, top = 0)`

```{r exercise2_merge, echo = T, eval = F}
# Exercise 2: Merging Tax Data

# 1. Basic Merge
# a) Create a left join of panel_vat and panel_cit by firm_id and year
# b) How many VAT records don't have matching CIT records?

# 2. Three-way Merge
# a) Start with your VAT-CIT merge from question 1
# b) Add firm characteristics (dt_firms)
# c) Keep all records from the VAT-CIT merge

# 3. Analysis After Merging
# Using your three-way merge:
# a) Calculate average VAT amount by firm size
# b) Find firms that have VAT but no CIT records
# c) Calculate the ratio of VAT to CIT for each firm (handle division by zero!)
```

---

## Exercise 2: Solutions {.exercise}

```{r solutions2_merge, echo = T, eval = T}
# Collapse VAT data to annual totals by firm
collapsed_vat <- panel_vat[, .(
  vat_amount = sum(net_vat, na.rm = TRUE),
  vat_outputs = sum(vat_outputs, na.rm = TRUE)
), by = .(firm_id, year)]

# Compute CIT as 30% of VAT outputs
collapsed_vat[, cit_amount := vat_outputs * 0.3]

# 1. Basic Merge
# a) Left join VAT and CIT (in this case already computed in same table)
vat_cit <- collapsed_vat[, .(firm_id, year, vat_amount, cit_amount)]

# b) Count missing CIT records (if any, e.g., vat_outputs was NA)
missing_cit_count <- vat_cit[is.na(cit_amount), .N]

# 2. Three-way Merge
# Add firm characteristics
full_data <- merge(
  vat_cit,
  dt_firms,
  by = c("firm_id", "year"),
  all.x = TRUE
)

# 3. Analysis
# a) Average VAT by size
avg_vat_by_size <- full_data[, .(avg_vat = mean(vat_amount, na.rm = TRUE)), by = size]

# b) Firms with VAT but no CIT
vat_only <- full_data[!is.na(vat_amount) & is.na(cit_amount)]
firms_vat_no_cit <- unique(vat_only$firm_id)[1:10]

# c) VAT to CIT ratio (safe division)
full_data[, vat_cit_ratio := ifelse(cit_amount > 0, vat_amount / cit_amount, NA)]


```

# Working with Multiple Columns {background-color="#07202E"}

---

## The .SD Concept

`.SD` stands for "Subset of Data" - it represents the columns you're working with:

```{r sd_basic, echo = T, eval = T}
# Calculate mean of all numeric columns
numeric_means <- panel_vat[, lapply(.SD, mean, na.rm = TRUE), 
                           .SDcols = c("vat_inputs", "vat_outputs", "net_vat")]

print(numeric_means)
```

::: {.callout-note}
`lapply()` applies a function (like `mean`) to each column in `.SD`.
:::

---

## Selecting Columns with .SDcols

Control which columns to process:

```{r sdcols_patterns, echo = T, eval = T}
# Method 1: List specific columns
panel_vat[, lapply(.SD, sum, na.rm = TRUE), 
         .SDcols = c("vat_inputs", "vat_outputs")]

# Method 2: Use patterns (columns starting with "vat")
panel_vat[, lapply(.SD, sum, na.rm = TRUE), 
         .SDcols = patterns("^vat")]

# Method 3: Select numeric columns only
numeric_cols <- names(panel_vat)[sapply(panel_vat, is.numeric)]
panel_vat[, lapply(.SD, mean, na.rm = TRUE), 
         .SDcols = numeric_cols]
```

---

## Practical Example: Standardizing Data

Standardize multiple columns at once:

```{r standardize, echo = T, eval = T}
# List columns to standardize
amount_cols <- c("vat_inputs", "vat_outputs", "net_vat")

# Create standardized versions
panel_vat[, paste0(amount_cols, "_std") := lapply(.SD, function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}), .SDcols = amount_cols]

# Check result
panel_vat[1:3, .(firm_id, vat_inputs, vat_inputs_std)]
```

::: {.callout-tip}
Standardizing means converting to a scale where mean = 0 and standard deviation = 1.
:::

---

## Exercise 3: Complete Analysis {.exercise}

`r countdown::countdown(minutes = 15, seconds = 0, top = 0)`

```{r exercise3_complete, echo = T, eval = F}
# Exercise 3: Complete Tax Analysis Workflow

# Scenario: Identify firms for audit based on unusual patterns

# 1. Data Preparation
# a) Merge panel_vat with dt_firms
# b) Calculate VAT efficiency (outputs/inputs) for each firm
# c) Add a flag for efficiency < 0.7 or > 1.3 (unusual patterns)

# 2. Industry Comparison
# a) Calculate average VAT efficiency by industry
# b) Add each firm's deviation from industry average
# c) Flag firms that deviate by more than 20%

# 3. Risk Scoring
# Create a risk score (0-3) based on:
# - Unusual efficiency: +1 point
# - Large industry deviation: +1 point  
# - Negative VAT balance: +1 point

# 4. Final Report
# Create a summary showing:
# - Number of high-risk firms (score >= 2) by industry
# - Total VAT amount at risk
# - Top 10 highest risk firms
```

---

## Exercise 3: Solutions {.exercise}

```{r solutions3_complete, echo = T, eval = T}
# 1. Data Preparation
# a) Merge data
analysis_data <- merge(panel_vat, dt_firms, by = c("firm_id", "year"))

# b) Calculate efficiency
analysis_data[, vat_efficiency := vat_outputs / vat_inputs]

# c) Flag unusual efficiency
analysis_data[, unusual_efficiency := vat_efficiency < 0.7 | vat_efficiency > 1.3]

# 2. Industry Comparison
# a) Industry averages
analysis_data[, industry_avg_eff := mean(vat_efficiency, na.rm = TRUE), by = industry]

# b) Deviation from average
analysis_data[, deviation := abs(vat_efficiency - industry_avg_eff) / industry_avg_eff]

# c) Flag large deviations
analysis_data[, large_deviation := deviation > 0.2]

# 3. Risk Scoring
analysis_data[, risk_score := 0]
analysis_data[unusual_efficiency == TRUE, risk_score := risk_score + 1]
analysis_data[large_deviation == TRUE, risk_score := risk_score + 1]
analysis_data[net_vat < 0, risk_score := risk_score + 1]

# 4. Final Report
# High-risk firms by industry
risk_summary <- analysis_data[risk_score >= 2, .(
  high_risk_firms = .N,
  vat_at_risk = sum(abs(net_vat), na.rm = TRUE)
), by = industry][order(-high_risk_firms)]

print(risk_summary)

# Top 10 highest risk
top_risks <- analysis_data[order(-risk_score, -abs(net_vat))][1:10, 
  .(firm_id, industry, risk_score, net_vat, vat_efficiency)]

print(top_risks)
```

# Building Efficient Workflows {background-color="#07202E"}

---

## Organizing Your Analysis

Structure your code for clarity and reusability:

```{r workflow_structure, echo = T, eval = F}
# 1. Load packages
library(data.table)
library(here)

# 2. Read data
vat_data <- fread(here("data", "vat_declarations.csv"))
firm_data <- fread(here("data", "firm_registry.csv"))

# 3. Clean and prepare
# - Fix data types
# - Handle missing values
# - Create derived columns

# 4. Analysis
# - Merge datasets
# - Calculate metrics
# - Generate reports

# 5. Save results
fwrite(results, here("outputs", "audit_candidates.csv"))
```

---

## Best Practices for Tax Data

**1. Always validate your data:**
```{r validate, echo = T, eval = T}
# Check for duplicates
duplicates <- panel_vat[duplicated(panel_vat, by = c("firm_id", "declaration_date"))]
if(nrow(duplicates) > 0) warning("Found duplicate declarations!")

# Check for negative values where they shouldn't exist
panel_vat[vat_inputs < 0, .N]  # Should be 0
```

**2. Document your assumptions:**
```{r document, echo = T, eval = F}
# VAT efficiency between 0.5 and 2.0 is considered normal
# Based on: tax administration guidelines 2023
normal_efficiency_range <- c(0.5, 2.0)
```

---

## Memory-Efficient Operations

When working with large datasets:

```{r memory_efficient, echo = T, eval = F}
# Good: Modify in place
large_data[, new_column := calculation]

# Less efficient: Creating copies
large_data <- large_data[, new_column := calculation]

# Delete columns you don't need
large_data[, unnecessary_column := NULL]

# Check memory usage
tables()
```

::: {.callout-tip}
Use `:=` to modify data in place - it saves memory!
:::

---

## Final Exercise: Build a Compliance Monitoring System {.exercise}

`r countdown::countdown(minutes = 20, seconds = 0, top = 0)`

```{r final_exercise, echo = T, eval = F}
# Final Challenge: Build a Compliance Monitoring System

# Your task: Create a system to identify compliance risks

# Requirements:
# 1. Data Integration
#    - Merge VAT, CIT, and firm data
#    - Handle missing data appropriately
#    - Create a unified view of each taxpayer

# 2. Risk Indicators (create at least 3)
#    - Late filing indicator
#    - Payment compliance rate
#    - Cross-tax consistency
#    - Size-appropriate tax amounts

# 3. Reporting
#    - Summary by industry and size
#    - List of top 20 highest risk firms
#    - Total tax revenue at risk

# 4. Output
#    - Save results as CSV files
#    - Create a summary statistics table

# Hint: Break this into smaller steps and test each part!
```

---

## Common Pitfalls and Solutions

**1. Column names don't exist:**
```{r pitfall1, echo = T, eval = F}
# Error: column 'VAT_Amount' not found
# Solution: Check exact names
names(panel_vat)  # List all column names
```

**2. Forgetting na.rm = TRUE:**
```{r pitfall2, echo = T, eval = F}
# Returns NA if any value is missing
mean(data$column)

# Correctly handles missing values  
mean(data$column, na.rm = TRUE)
```

**3. Merge produces too many/few rows:**
```{r pitfall3, echo = T, eval = F}
# Check your merge keys are unique
data[, .N, by = .(firm_id, year)][N > 1]  # Find duplicates
```

---

## Key Takeaways

**You've learned to:**
- Use data.table's powerful `DT[i, j, by]` syntax
- Filter, select, and transform tax data efficiently
- Merge multiple data sources
- Create summary statistics and reports
- Build complete analysis workflows

**Remember:**
- data.table is fast and memory-efficient
- The syntax is similar to SQL
- Use `:=` for in-place modifications
- Chain operations with `][`

---

## Resources for Continued Learning

**Official Documentation:**
- [data.table Introduction](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html)
- [FAQ with examples](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-faq.html)

**Cheat Sheets:**
- [data.table Cheat Sheet](https://raw.githubusercontent.com/rstudio/cheatsheets/master/datatable.pdf)

**For SQL Users:**
- [data.table for SQL users](https://atrebas.github.io/post/2019-03-03-datatable-dplyr/#sql-syntax)

::: {.callout-tip}
Practice with small datasets first, then apply to your real tax data!
:::

---

## Thank You! {.center}

**You're now equipped to:**
- Process large tax datasets efficiently
- Perform complex data operations
- Create reproducible analyses
- Build data-driven compliance systems

**Next steps:**
1. Practice these techniques with your own data
2. Start with simple operations, build complexity gradually
3. Share your code with colleagues
4. Ask questions when stuck!

::: {.callout-note}
## Remember
Always follow your organization's data privacy and security policies when working with taxpayer data.
:::

**Questions?** `r emo::ji("raised_hand")`
```